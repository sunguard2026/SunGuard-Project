{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5990acd9-be04-43e2-a687-d3ea8820920a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "# ===== cell 0: config =====\n",
    "from pathlib import Path\n",
    "import torch, torch.nn as nn, random, numpy as np\n",
    "\n",
    "# paths\n",
    "DATA_DIR = Path(\"severe cases/HMI_continuum\")\n",
    "RUN_DIR  = Path(\"./wgangp_128\")\n",
    "(RUN_DIR/\"samples\").mkdir(parents=True, exist_ok=True)\n",
    "(RUN_DIR/\"ckpt\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# model\n",
    "image_size = 128\n",
    "nc = 1          # 1=grayscale, 3=RGB\n",
    "nz = 128        # latent size\n",
    "ngf = 160       # generator width (keep if you used 160 earlier)\n",
    "ndf = 128       # discriminator width\n",
    "\n",
    "# training\n",
    "batch_size = 64                # drop to 64 if OOM\n",
    "num_epochs = 150               # total epochs target\n",
    "n_critic   = 3                 # D steps per G step (classic WGAN-GP)\n",
    "lambda_gp  = 5.0              # gradient penalty coefficient\n",
    "lr_g = 1.5e-4; lr_d = 8e-5     # WGAN-GP rec: betas=(0.0, 0.9)1e-4 \n",
    "beta1, beta2 = 0.0, 0.9\n",
    "mixed_precision = True\n",
    "\n",
    "# reproducibility\n",
    "seed = 42\n",
    "random.seed(seed); np.random.seed(seed); torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99d25bf2-d59f-482b-b04e-9f0142af3b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images: 2705 | batches/epoch: 42\n"
     ]
    }
   ],
   "source": [
    "# ===== cell 1: dataset =====\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image, ImageEnhance\n",
    "import os, random\n",
    "\n",
    "class EnhanceContrast:\n",
    "    def __init__(self, p=0.4, factor_range=(1.1,1.4)): self.p=p; self.fr=factor_range\n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.p:\n",
    "            return ImageEnhance.Contrast(img).enhance(random.uniform(*self.fr))\n",
    "        return img\n",
    "\n",
    "class FlatImageFolder(Dataset):\n",
    "    def __init__(self, root, transform=None, exts=(\".jpg\",\".jpeg\",\".png\",\".tif\",\".tiff\",\".bmp\")):\n",
    "        p = Path(root)\n",
    "        self.paths = [p/f for f in os.listdir(p) if (p/f).is_file() and (p/f).suffix.lower() in exts]\n",
    "        if not self.paths: raise RuntimeError(f\"No images found in {root}\")\n",
    "        self.transform = transform\n",
    "    def __len__(self): return len(self.paths)\n",
    "    def __getitem__(self, i):\n",
    "        img = Image.open(self.paths[i]).convert(\"RGB\")\n",
    "        return self.transform(img)\n",
    "\n",
    "aug = [\n",
    "    # transforms.RandomHorizontalFlip(0.5),\n",
    "    # transforms.RandomVerticalFlip(0.5),\n",
    "    # transforms.RandomAffine(degrees=10, translate=(0.05,0.05), scale=(0.95,1.05)),\n",
    "    # EnhanceContrast(0.5, (1.1,1.5)),\n",
    "]\n",
    "\n",
    "tfm = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1) if nc==1 else transforms.Lambda(lambda x: x),\n",
    "    *aug,\n",
    "    transforms.Resize((image_size, image_size), interpolation=Image.BICUBIC),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*nc, [0.5]*nc),  # [-1,1]\n",
    "])\n",
    "\n",
    "ds = FlatImageFolder(DATA_DIR, transform=tfm)\n",
    "dl = DataLoader(ds, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=2, pin_memory=True)\n",
    "print(\"images:\", len(ds), \"| batches/epoch:\", len(dl))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "218a5132-c551-4e2f-9513-8c30280446b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G params (M): 127.479681\n",
      "D params (M): 44.599296\n"
     ]
    }
   ],
   "source": [
    "# ===== Generator (ResNet-style upsampling + Self-Attention at 32x32) =====\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import spectral_norm as SN\n",
    "\n",
    "\n",
    "# ---------- helper blocks ----------\n",
    "def weights_init_dcgan(m):\n",
    "    name = m.__class__.__name__\n",
    "    if \"Conv\" in name and hasattr(m, \"weight\"):\n",
    "        nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "        if getattr(m, \"bias\", None) is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "    elif \"BatchNorm\" in name:\n",
    "        if hasattr(m, \"weight\") and m.weight is not None:\n",
    "            nn.init.normal_(m.weight, 1.0, 0.02)\n",
    "        if hasattr(m, \"bias\") and m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "class ResUpBlock(nn.Module):\n",
    "    \"\"\"Upsample x2 with nearest, then 2 convs + residual skip.\"\"\"\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, 1, 1, bias=False)\n",
    "        self.bn1   = nn.BatchNorm2d(out_ch)\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, 1, 1, bias=False)\n",
    "        self.bn2   = nn.BatchNorm2d(out_ch)\n",
    "        self.skip  = nn.Conv2d(in_ch, out_ch, 1, 1, 0, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.interpolate(x, scale_factor=2, mode='nearest')\n",
    "        out = self.conv1(x); out = self.bn1(out); out = F.relu(out, inplace=True)\n",
    "        out = self.conv2(out); out = self.bn2(out)\n",
    "        skip = self.skip(x)\n",
    "        return F.relu(out + skip, inplace=True)\n",
    "\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    \"\"\"Simple self-attention block.\"\"\"\n",
    "    def __init__(self, ch, sn=False):\n",
    "        super().__init__()\n",
    "        conv = (lambda *a, **k: SN(nn.Conv2d(*a, **k))) if sn else nn.Conv2d\n",
    "        self.f = conv(ch, ch//8, 1, bias=False)\n",
    "        self.g = conv(ch, ch//8, 1, bias=False)\n",
    "        self.h = conv(ch, ch//2, 1, bias=False)\n",
    "        self.v = conv(ch//2, ch, 1, bias=False)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b,c,H,W = x.size()\n",
    "        f = self.f(x).view(b,-1,H*W)\n",
    "        g = self.g(x).view(b,-1,H*W)\n",
    "        beta = torch.softmax(torch.bmm(f.transpose(1,2), g), dim=-1)\n",
    "        h_ = self.h(x).view(b,-1,H*W)\n",
    "        o = torch.bmm(h_, beta).view(b,-1,H,W)\n",
    "        o = self.v(o)\n",
    "        return self.gamma * o + x\n",
    "\n",
    "\n",
    "# ---------- main generator ----------\n",
    "class Generator128_Res(nn.Module):\n",
    "    def __init__(self, nz, ngf, nc):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.ConvTranspose2d(nz, ngf*16, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf*16), nn.ReLU(True),\n",
    "            nn.Conv2d(ngf*16, ngf*16, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*16), nn.ReLU(True),\n",
    "        )\n",
    "        self.b1 = ResUpBlock(ngf*16, ngf*8)   # 4 -> 8\n",
    "        self.b2 = ResUpBlock(ngf*8,  ngf*4)   # 8 -> 16\n",
    "        self.b3 = ResUpBlock(ngf*4,  ngf*2)   # 16 -> 32\n",
    "\n",
    "        # âœ… <--- this is where we add attention (32x32 resolution)\n",
    "        self.attn32 = SelfAttention(ngf*2, sn=False)\n",
    "\n",
    "        self.b4 = ResUpBlock(ngf*2,  ngf)     # 32 -> 64\n",
    "        self.to_rgb = nn.Sequential(\n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),  # 64 -> 128\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = self.fc(z)\n",
    "        x = self.b1(x)       # 4 -> 8\n",
    "        x = self.b2(x)       # 8 -> 16\n",
    "        x = self.b3(x)       # 16 -> 32\n",
    "        x = self.attn32(x)   # <-- attention here\n",
    "        x = self.b4(x)       # 32 -> 64\n",
    "        x = self.to_rgb(x)   # 64 -> 128\n",
    "        return x\n",
    "\n",
    "class Discriminator128(nn.Module):\n",
    "    # 128 -> 64 -> 32 -> 16 -> 8 -> 4 -> 1  (no BN)\n",
    "    def __init__(self, ndf, nc):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(nc,     ndf,    4,2,1, bias=False), nn.LeakyReLU(0.2, True),  # 128->64\n",
    "            nn.Conv2d(ndf,    ndf*2,  4,2,1, bias=False), nn.LeakyReLU(0.2, True),  # 64->32\n",
    "            nn.Conv2d(ndf*2,  ndf*4,  4,2,1, bias=False), nn.LeakyReLU(0.2, True),  # 32->16\n",
    "            nn.Conv2d(ndf*4,  ndf*8,  4,2,1, bias=False), nn.LeakyReLU(0.2, True),  # 16->8\n",
    "            nn.Conv2d(ndf*8,  ndf*16, 4,2,1, bias=False), nn.LeakyReLU(0.2, True),  # 8->4\n",
    "            nn.Conv2d(ndf*16, 1,      4,1,0, bias=False),                           # 4->1  (linear output)\n",
    "        )\n",
    "    def forward(self, x): return self.net(x).view(-1)\n",
    "\n",
    "G = Generator128_Res(nz, ngf, nc).to(device); G.apply(weights_init_dcgan)\n",
    "D = Discriminator128(ndf, nc).to(device);  D.apply(weights_init_dcgan)\n",
    "\n",
    "optG = torch.optim.Adam(G.parameters(), lr=lr_g, betas=(beta1, beta2))\n",
    "optD = torch.optim.Adam(D.parameters(), lr=lr_d, betas=(beta1, beta2))\n",
    "\n",
    "print(\"G params (M):\", sum(p.numel() for p in G.parameters())/1e6)\n",
    "print(\"D params (M):\", sum(p.numel() for p in D.parameters())/1e6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4e30d2b-5da3-45a5-b536-d99202d829ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMP API: new | AMP enabled: True\n"
     ]
    }
   ],
   "source": [
    "# ===== cell 3: AMP =====\n",
    "import inspect\n",
    "from functools import partial\n",
    "\n",
    "has_new_amp = hasattr(torch, \"amp\") and hasattr(torch.amp, \"autocast\")\n",
    "if has_new_amp:\n",
    "    from torch import amp as _amp\n",
    "    autocast_cm = partial(_amp.autocast, device_type=\"cuda\")\n",
    "    _GradScaler = _amp.GradScaler\n",
    "    if \"device_type\" in inspect.signature(_GradScaler).parameters:\n",
    "        scaler = _GradScaler(device_type=\"cuda\", enabled=(mixed_precision and torch.cuda.is_available()))\n",
    "    else:\n",
    "        scaler = _GradScaler(enabled=(mixed_precision and torch.cuda.is_available()))\n",
    "else:\n",
    "    from torch.cuda.amp import autocast as legacy_autocast, GradScaler as LegacyGradScaler\n",
    "    autocast_cm = partial(legacy_autocast)\n",
    "    scaler = LegacyGradScaler(enabled=(mixed_precision and torch.cuda.is_available()))\n",
    "\n",
    "use_amp = (getattr(scaler, \"is_enabled\", lambda: False)()) or (mixed_precision and torch.cuda.is_available())\n",
    "print(f\"AMP API: {'new' if has_new_amp else 'legacy'} | AMP enabled: {use_amp}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cdad9fa-9234-4a81-8293-dcc3c806a277",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_122774/1221044864.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  g_state = torch.load(last, map_location=device)\n",
      "/tmp/ipykernel_122774/1221044864.py:66: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  d_state = torch.load(str(last).replace(\"_G.pt\",\"_D.pt\"), map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resume] scaler restored\n",
      "[resume] loaded epoch 440 â†’ continue from 441\n"
     ]
    }
   ],
   "source": [
    "# ===== cell 4: losses & utils =====\n",
    "num_epochs = 500\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "def d_wgan_loss(d_real, d_fake):\n",
    "    # maximize D(real) - D(fake) -> minimize (fake - real)\n",
    "    return d_fake.mean() - d_real.mean()\n",
    "\n",
    "def g_wgan_loss(d_fake):\n",
    "    # maximize D(fake) -> minimize -D(fake)\n",
    "    return -d_fake.mean()\n",
    "\n",
    "def gradient_penalty(D, real, fake):\n",
    "    b = real.size(0)\n",
    "    eps = torch.rand(b, 1, 1, 1, device=real.device)\n",
    "    x_hat = eps * real + (1 - eps) * fake\n",
    "    x_hat.requires_grad_(True)\n",
    "    d_hat = D(x_hat)\n",
    "    grad = torch.autograd.grad(d_hat.sum(), x_hat, create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    gp = (grad.view(b, -1).norm(2, dim=1) - 1.0).pow(2).mean()\n",
    "    return gp\n",
    "\n",
    "# display helpers (clear grids)\n",
    "def _to_display(x, mode=\"linear\", eps=1e-6):\n",
    "    if mode == \"linear\":\n",
    "        y = (x + 1) / 2\n",
    "    elif mode == \"stretch\":\n",
    "        B = x.size(0); flat = x.view(B, -1)\n",
    "        mn = flat.min(dim=1, keepdim=True).values; mx = flat.max(dim=1, keepdim=True).values\n",
    "        y = ((flat - mn) / (mx - mn + eps)).view_as(x)\n",
    "    else:\n",
    "        y = (x + 1) / 2\n",
    "    return y.clamp(0,1)\n",
    "\n",
    "fixed_z = torch.randn(128, nz, 1, 1, device=device)\n",
    "\n",
    "def save_samples(epoch, model=None, nrow=16, vis_mode=\"stretch\"):\n",
    "    model = model or G\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x = model(fixed_z.to(next(model.parameters()).device))\n",
    "        v = _to_display(x, mode=vis_mode)\n",
    "    save_image(v, RUN_DIR/f\"samples/epoch_{epoch:04d}.png\", nrow=nrow)\n",
    "    model.train()\n",
    "\n",
    "# ckpt (with scaler state)\n",
    "def save_ckpt(epoch, scaler_obj=None):\n",
    "    g_tmp = RUN_DIR/\"ckpt\"/f\".tmp_epoch_{epoch:04d}_G.pt\"\n",
    "    d_tmp = RUN_DIR/\"ckpt\"/f\".tmp_epoch_{epoch:04d}_D.pt\"\n",
    "    g_dst = RUN_DIR/\"ckpt\"/f\"epoch_{epoch:04d}_G.pt\"\n",
    "    d_dst = RUN_DIR/\"ckpt\"/f\"epoch_{epoch:04d}_D.pt\"\n",
    "    torch.save({\"epoch\":epoch, \"G\":G.state_dict(), \"optG\":optG.state_dict(),\n",
    "                \"scaler\": (scaler_obj.state_dict() if scaler_obj is not None else None)}, g_tmp)\n",
    "    torch.save({\"epoch\":epoch, \"D\":D.state_dict(), \"optD\":optD.state_dict()}, d_tmp)\n",
    "    import os; os.replace(g_tmp, g_dst); os.replace(d_tmp, d_dst)\n",
    "    print(f\"[ckpt] saved {epoch:04d}\")\n",
    "\n",
    "def resume_if_any():\n",
    "    import re\n",
    "    ckpts = sorted((RUN_DIR/\"ckpt\").glob(\"epoch_*_G.pt\"))\n",
    "    if not ckpts: print(\"[resume] none\"); return 1\n",
    "    last = ckpts[-1]\n",
    "    e = int(re.search(r\"epoch_(\\d+)_G\\.pt\", last.name).group(1))\n",
    "    g_state = torch.load(last, map_location=device)\n",
    "    d_state = torch.load(str(last).replace(\"_G.pt\",\"_D.pt\"), map_location=device)\n",
    "    G.load_state_dict(g_state[\"G\"]); D.load_state_dict(d_state[\"D\"])\n",
    "    optG.load_state_dict(g_state[\"optG\"]); optD.load_state_dict(d_state[\"optD\"])\n",
    "    if \"scaler\" in g_state and g_state[\"scaler\"] is not None:\n",
    "        try: scaler.load_state_dict(g_state[\"scaler\"]); print(\"[resume] scaler restored\")\n",
    "        except Exception as e2: print(\"[resume] scaler not restored:\", e2)\n",
    "    print(f\"[resume] loaded epoch {e} â†’ continue from {e+1}\")\n",
    "    return e+1\n",
    "\n",
    "start_epoch = resume_if_any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44d25a14-1ce9-415a-b866-70d8c77fb1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[441/500] Wâ‰ˆ7.45 | Dreal=9.09 | Dfake=1.64 | GP=0.37 | G=-0.1809\n",
      "[442/500] Wâ‰ˆ8.76 | Dreal=8.56 | Dfake=-0.20 | GP=0.50 | G=1.4968\n",
      "[443/500] Wâ‰ˆ8.02 | Dreal=11.43 | Dfake=3.41 | GP=0.46 | G=-0.1995\n",
      "[444/500] Wâ‰ˆ7.04 | Dreal=8.18 | Dfake=1.14 | GP=0.31 | G=1.3479\n",
      "[445/500] Wâ‰ˆ7.45 | Dreal=8.38 | Dfake=0.93 | GP=0.39 | G=0.1622\n",
      "[446/500] Wâ‰ˆ6.52 | Dreal=8.40 | Dfake=1.88 | GP=0.30 | G=-0.8682\n",
      "[447/500] Wâ‰ˆ7.65 | Dreal=9.00 | Dfake=1.35 | GP=0.41 | G=-1.3803\n",
      "[448/500] Wâ‰ˆ8.48 | Dreal=10.11 | Dfake=1.63 | GP=0.48 | G=0.5639\n",
      "[449/500] Wâ‰ˆ8.26 | Dreal=7.92 | Dfake=-0.34 | GP=0.44 | G=0.9655\n",
      "[450/500] Wâ‰ˆ7.83 | Dreal=10.38 | Dfake=2.55 | GP=0.37 | G=0.2133\n",
      "[ckpt] saved 0450\n",
      "[451/500] Wâ‰ˆ7.15 | Dreal=7.83 | Dfake=0.68 | GP=0.36 | G=1.4044\n",
      "[452/500] Wâ‰ˆ8.43 | Dreal=8.83 | Dfake=0.39 | GP=0.46 | G=2.5385\n",
      "[453/500] Wâ‰ˆ7.19 | Dreal=6.16 | Dfake=-1.03 | GP=0.38 | G=2.3958\n",
      "[454/500] Wâ‰ˆ7.60 | Dreal=9.84 | Dfake=2.24 | GP=0.38 | G=0.8866\n",
      "[455/500] Wâ‰ˆ7.86 | Dreal=9.81 | Dfake=1.96 | GP=0.39 | G=-0.4436\n",
      "[456/500] Wâ‰ˆ7.95 | Dreal=9.95 | Dfake=2.00 | GP=0.43 | G=-0.9942\n",
      "[457/500] Wâ‰ˆ8.79 | Dreal=11.15 | Dfake=2.36 | GP=0.54 | G=1.5313\n",
      "[458/500] Wâ‰ˆ8.59 | Dreal=8.47 | Dfake=-0.12 | GP=0.45 | G=1.2959\n",
      "[459/500] Wâ‰ˆ9.22 | Dreal=8.15 | Dfake=-1.06 | GP=0.54 | G=2.6296\n",
      "[460/500] Wâ‰ˆ7.64 | Dreal=8.23 | Dfake=0.59 | GP=0.39 | G=0.4055\n",
      "[ckpt] saved 0460\n",
      "[461/500] Wâ‰ˆ7.38 | Dreal=8.32 | Dfake=0.95 | GP=0.35 | G=0.2913\n",
      "[462/500] Wâ‰ˆ7.43 | Dreal=9.82 | Dfake=2.40 | GP=0.37 | G=1.7318\n",
      "[463/500] Wâ‰ˆ9.81 | Dreal=10.97 | Dfake=1.16 | GP=0.59 | G=0.7306\n",
      "[464/500] Wâ‰ˆ7.69 | Dreal=7.63 | Dfake=-0.06 | GP=0.39 | G=1.5045\n",
      "[465/500] Wâ‰ˆ9.01 | Dreal=11.67 | Dfake=2.66 | GP=0.50 | G=-1.1835\n",
      "[466/500] Wâ‰ˆ8.85 | Dreal=10.08 | Dfake=1.23 | GP=0.47 | G=0.5792\n",
      "[467/500] Wâ‰ˆ8.30 | Dreal=9.45 | Dfake=1.15 | GP=0.44 | G=-0.0391\n",
      "[468/500] Wâ‰ˆ7.52 | Dreal=5.28 | Dfake=-2.23 | GP=0.39 | G=3.2601\n",
      "[469/500] Wâ‰ˆ7.90 | Dreal=7.56 | Dfake=-0.34 | GP=0.40 | G=2.5115\n",
      "[470/500] Wâ‰ˆ7.66 | Dreal=8.14 | Dfake=0.48 | GP=0.40 | G=0.4582\n",
      "[ckpt] saved 0470\n",
      "[471/500] Wâ‰ˆ8.45 | Dreal=14.46 | Dfake=6.01 | GP=0.47 | G=-3.1876\n",
      "[472/500] Wâ‰ˆ7.81 | Dreal=6.36 | Dfake=-1.45 | GP=0.39 | G=2.5739\n",
      "[473/500] Wâ‰ˆ6.59 | Dreal=7.87 | Dfake=1.28 | GP=0.30 | G=0.7438\n",
      "[474/500] Wâ‰ˆ7.71 | Dreal=9.17 | Dfake=1.46 | GP=0.36 | G=0.8733\n",
      "[475/500] Wâ‰ˆ9.06 | Dreal=10.42 | Dfake=1.36 | GP=0.51 | G=0.2463\n",
      "[476/500] Wâ‰ˆ8.88 | Dreal=11.84 | Dfake=2.97 | GP=0.48 | G=-0.6621\n",
      "[477/500] Wâ‰ˆ8.71 | Dreal=11.26 | Dfake=2.55 | GP=0.47 | G=0.1674\n",
      "[478/500] Wâ‰ˆ7.40 | Dreal=5.90 | Dfake=-1.50 | GP=0.39 | G=2.7411\n",
      "[479/500] Wâ‰ˆ7.78 | Dreal=10.34 | Dfake=2.56 | GP=0.40 | G=-1.7909\n",
      "[480/500] Wâ‰ˆ8.95 | Dreal=8.90 | Dfake=-0.05 | GP=0.51 | G=0.8737\n",
      "[ckpt] saved 0480\n",
      "[481/500] Wâ‰ˆ7.60 | Dreal=9.35 | Dfake=1.75 | GP=0.40 | G=-0.3584\n",
      "[482/500] Wâ‰ˆ8.02 | Dreal=9.49 | Dfake=1.47 | GP=0.46 | G=-0.7406\n",
      "[483/500] Wâ‰ˆ7.09 | Dreal=8.30 | Dfake=1.21 | GP=0.40 | G=1.0911\n",
      "[484/500] Wâ‰ˆ8.40 | Dreal=11.79 | Dfake=3.39 | GP=0.45 | G=-2.2899\n",
      "[485/500] Wâ‰ˆ10.15 | Dreal=8.08 | Dfake=-2.07 | GP=0.63 | G=2.6934\n",
      "[486/500] Wâ‰ˆ8.48 | Dreal=8.20 | Dfake=-0.28 | GP=0.47 | G=0.2225\n",
      "[487/500] Wâ‰ˆ8.88 | Dreal=9.41 | Dfake=0.53 | GP=0.49 | G=0.7435\n",
      "[488/500] Wâ‰ˆ8.36 | Dreal=12.24 | Dfake=3.88 | GP=0.46 | G=-1.5960\n",
      "[489/500] Wâ‰ˆ9.24 | Dreal=9.49 | Dfake=0.26 | GP=0.54 | G=2.3302\n",
      "[490/500] Wâ‰ˆ8.76 | Dreal=9.80 | Dfake=1.04 | GP=0.47 | G=0.7102\n",
      "[ckpt] saved 0490\n",
      "[491/500] Wâ‰ˆ6.56 | Dreal=8.61 | Dfake=2.05 | GP=0.35 | G=-0.1022\n",
      "[492/500] Wâ‰ˆ7.16 | Dreal=8.86 | Dfake=1.71 | GP=0.35 | G=1.2095\n",
      "[493/500] Wâ‰ˆ7.72 | Dreal=9.52 | Dfake=1.81 | GP=0.39 | G=-1.7042\n",
      "[494/500] Wâ‰ˆ8.17 | Dreal=10.26 | Dfake=2.09 | GP=0.41 | G=0.5740\n",
      "[495/500] Wâ‰ˆ8.18 | Dreal=7.73 | Dfake=-0.45 | GP=0.42 | G=2.0001\n",
      "[496/500] Wâ‰ˆ8.31 | Dreal=8.88 | Dfake=0.57 | GP=0.61 | G=1.1820\n",
      "[497/500] Wâ‰ˆ8.93 | Dreal=8.77 | Dfake=-0.16 | GP=0.52 | G=3.2020\n",
      "[498/500] Wâ‰ˆ9.53 | Dreal=8.05 | Dfake=-1.47 | GP=0.58 | G=4.3094\n",
      "[499/500] Wâ‰ˆ8.48 | Dreal=9.40 | Dfake=0.92 | GP=0.48 | G=0.1841\n",
      "[500/500] Wâ‰ˆ7.79 | Dreal=8.65 | Dfake=0.86 | GP=0.40 | G=1.2319\n",
      "[ckpt] saved 0500\n",
      "[ckpt] saved 0500\n",
      "âœ… training complete\n"
     ]
    }
   ],
   "source": [
    "# ===== cell 5: training (improved with detailed logging) =====\n",
    "\n",
    "try:\n",
    "    global_step = 0\n",
    "    for epoch in range(start_epoch, num_epochs + 1):\n",
    "        G.train(); D.train()\n",
    "\n",
    "        # New meters for detailed logging\n",
    "        d_meter = g_meter = 0.0\n",
    "        dreal_meter = dfake_meter = w_meter = gp_meter = 0.0\n",
    "\n",
    "        for real in dl:\n",
    "            real = real.to(device, non_blocking=True)\n",
    "            b = real.size(0)\n",
    "\n",
    "            # --- train D n_critic times ---\n",
    "            for _ in range(n_critic):\n",
    "                optD.zero_grad(set_to_none=True)\n",
    "                if use_amp:\n",
    "                    with autocast_cm(enabled=True):\n",
    "                        z = torch.randn(b, nz, 1, 1, device=device)\n",
    "                        fake = G(z).detach()\n",
    "\n",
    "                        d_real = D(real)\n",
    "                        d_fake = D(fake)\n",
    "                        loss_d = d_wgan_loss(d_real, d_fake)\n",
    "                        gp = gradient_penalty(D, real, fake)\n",
    "                        d_loss = loss_d + lambda_gp * gp\n",
    "\n",
    "                        # --- logging additions ---\n",
    "                        d_real_mean = d_real.mean().item()\n",
    "                        d_fake_mean = d_fake.mean().item()\n",
    "                        gp_val = gp.item()\n",
    "                        wasserstein = d_real_mean - d_fake_mean\n",
    "                        dreal_meter += d_real_mean\n",
    "                        dfake_meter += d_fake_mean\n",
    "                        w_meter += wasserstein\n",
    "                        gp_meter += gp_val\n",
    "                        # ---------------------------\n",
    "\n",
    "                    scaler.scale(d_loss).backward()\n",
    "                    scaler.step(optD); scaler.update()\n",
    "                else:\n",
    "                    z = torch.randn(b, nz, 1, 1, device=device)\n",
    "                    fake = G(z).detach()\n",
    "                    d_real = D(real); d_fake = D(fake)\n",
    "                    loss_d = d_wgan_loss(d_real, d_fake)\n",
    "                    gp = gradient_penalty(D, real, fake)\n",
    "                    d_loss = loss_d + lambda_gp * gp\n",
    "\n",
    "                    # --- logging additions ---\n",
    "                    d_real_mean = d_real.mean().item()\n",
    "                    d_fake_mean = d_fake.mean().item()\n",
    "                    gp_val = gp.item()\n",
    "                    wasserstein = d_real_mean - d_fake_mean\n",
    "                    dreal_meter += d_real_mean\n",
    "                    dfake_meter += d_fake_mean\n",
    "                    w_meter += wasserstein\n",
    "                    gp_meter += gp_val\n",
    "                    # ---------------------------\n",
    "\n",
    "                    d_loss.backward(); optD.step()\n",
    "\n",
    "                d_meter += float(d_loss.detach().cpu())\n",
    "                global_step += 1\n",
    "\n",
    "            # --- train G once ---\n",
    "            optG.zero_grad(set_to_none=True)\n",
    "            if use_amp:\n",
    "                with autocast_cm(enabled=True):\n",
    "                    z = torch.randn(b, nz, 1, 1, device=device)\n",
    "                    fake = G(z)\n",
    "                    d_fake = D(fake)\n",
    "                    g_loss = g_wgan_loss(d_fake)\n",
    "                scaler.scale(g_loss).backward()\n",
    "                scaler.step(optG); scaler.update()\n",
    "            else:\n",
    "                z = torch.randn(b, nz, 1, 1, device=device)\n",
    "                fake = G(z); d_fake = D(fake)\n",
    "                g_loss = g_wgan_loss(d_fake)\n",
    "                g_loss.backward(); optG.step()\n",
    "\n",
    "            g_meter += float(g_loss.detach().cpu())\n",
    "\n",
    "        # --- end of epoch summary ---\n",
    "        n_batches = len(dl) * n_critic\n",
    "        print(f\"[{epoch:03d}/{num_epochs}] \"\n",
    "              f\"Wâ‰ˆ{w_meter/n_batches:.2f} | \"\n",
    "              f\"Dreal={dreal_meter/n_batches:.2f} | \"\n",
    "              f\"Dfake={dfake_meter/n_batches:.2f} | \"\n",
    "              f\"GP={gp_meter/n_batches:.2f} | \"\n",
    "              f\"G={g_meter/len(dl):.4f}\")\n",
    "\n",
    "        # --- save samples + checkpoints ---\n",
    "        save_samples(epoch, model=G, nrow=16, vis_mode=\"stretch\")\n",
    "        if epoch % 10 == 0:\n",
    "            save_ckpt(epoch, scaler_obj=scaler)\n",
    "\n",
    "    save_ckpt(num_epochs, scaler_obj=scaler)\n",
    "    print(\"âœ… training complete\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nðŸ›‘ interrupted â€” savingâ€¦\")\n",
    "    try:\n",
    "        save_ckpt(epoch, scaler_obj=scaler)\n",
    "    except:\n",
    "        save_ckpt(0, scaler_obj=scaler)\n",
    "    print(\"âœ… saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1259fe-8a20-4812-9685-899d733aa748",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
